# Практика 2: Профилирование и бенчмаркинг

[![Feedback](feedback.png)][feedback_day2]

## Цели

__Цель данной работы__ — познакомиться с source-level подходом к профилированию,
практикой написания тестов на производительность, их запуском и анализом метрик
производительности. В результате выполнения практического задания должно
сформироваться общее представление о поиске узких мест в приложении и процессе
бенчмаркинга, в данном случае понимаемого как регрессионное тестирование
производительности.

## Задачи

  1. Проанализировать время работы фильтра скелетонизации, понять сколько
     времени потребляет каждая из функций. Определить самые медленные функции,
     которые требуют оптимизации.
  1. Реализовать набор тестов на производительность. В первую очередь должны
     тестироваться сценарии, похожие на тот, который возникает в
     демо-приложении. Это важно, поскольку именно их мы впоследствии будем
     оптимизировать. Кроме того, следует добавить и другие тесты на
     производительность, чтобы отслеживать изменение производительности в целом.
  1. Собрать несколько отчетов с метриками производительности. В частности,
     можно проанализировать, насколько замедляет приложение сохранение
     изображений и замеры времени. Построить сравнительный отчет.

## Общая последовательность действий

  1. Инструментируем функцию `skeletonize` замерами времени (макросы `TS` и
     `TE`). Запускаем демо-приложение и анализируем время работы каждого шага.
     Проверяем, что сумма шагов примерно равна общему времени работы приложения.
     Запускаем приложение несколько раз и смотрим на разброс значений.
  1. Прежде чем учиться писать тесты производительности, стоит научиться их
     запускать и анализировать собранные метрики. Для этого запускаем сборку
     `perf_skeleton` с опцией сохранения XML-отчета. Затем анализируем метрики
     при помощи скриптов из OpenCV (`report.py`, `summary.py`). Детальные
     инструкции можно найти [здесь][using-perf-tests]. Также полезно сохранить
     несколько отчетов, и сравнить их друг с другом. Разброс значений стоит
     сопоставить с тем, что мы наблюдали при запуске демо-приложения.
  1. Далее пишем тест производительности на функцию `skeletonize`. Это делается
     в файле `perf/perf_skeleton`. Инструкции можно посмотреть в
     [документации][writing-perf-tests] к OpenCV. Проверяем, что время работы
     теста примерно равно тому времени, которое мы видели в консоли. Если
     имеются существенные различия, стараемся добиться похожих результатов,
     как правило разница в параметрах вызова функций.
  1. В качестве последнего шага стоит реализовать тесты производительности на
     три основных шага алгоритма: функции `ConvertColor_BGR2GRAY_BT709`,
     `ImageResize` и `GuoHallThinning`. Здесь также необходимо имитировать
     сценарий использования, аналогичный тому, что был в демо-приложении, чтобы
     получить похожие времена работы. Именно эти тесты впоследствии должны
     использоваться для анализа ваших ускорений.

## Детальная инструкция по выполнению работы

### Получение актуальной версии исходных файлов

Прежде чем приступить к выполнению практической работы, рекомендуется получить
свежие версии файлов из центрального репозитория. Это обычный шаг, с этого как
правило начинают день программисты. И сразу же рекомендуется создать новую ветку
для выполнения второго практического задания.

  ```txt
  $ cd <itseez-ws-2016-practice>
  $ git remote -v             # Проверяем что репозиторий upstream сконфигурирован
  $ git checkout master       # Извлекаем локальную ветку master
  $ git pull upstream master  # Вливаем изменения из центрального репозитория
  $ git checkout -b profiling-and-benchmarking  # Создаем новую рабочую ветку
  ```

Обращаем внимание, что в данном случае предполагается, что вы не делали коммитов
в ветку `master`, а работали исключительно в отдельных ветках. Если это не так,
то инструкция будет несколько иной. Например, можно удалить ветку `master` и
создать ее заново:

  ```txt
  $ cd <itseez-ws-2016-practice>
  $ git remote -v               # Проверяем что репозиторий upstream сконфигурирован
  $ git checkout master         # Извлекаем локальную ветку master
  $ git branch -m master-backup # Сохраняем текущий master под новым именем
  $ git remote update           # Получаем обновления из удаленных репозиториев
  $ git checkout -b master upstream/master      # Создаем новый локальный master
  $ git checkout -b profiling-and-benchmarking  # Создаем новую рабочую ветку
  ```

Ну и на самом деле при желании можно вообще не задействовать ветку `master`:

  ```txt
  $ cd <itseez-ws-2016-practice>
  $ git remote -v     # Проверяем что репозиторий upstream сконфигурирован
  $ git remote update # Получаем обновления из удаленных репозиториев
  $ git checkout -b profiling-and-benchmarking upstream/master  # Создаем новую рабочую ветку
  ```

### Профилирование

  1. Далее нужно выполнить инструментацию функции `skeletonize` замерами
     времени, чтобы понять, на что тратится время внутри нее. Для этого
     открываем ее код и обрамляем основные функции макросами `TS` и `TE`, как
     это сделано для функции `imwrite`.

  1. После этого нужно построить и запустить демо-приложение. Первое, в чем
     нужно убедиться, это что сумма времени работы отдельных функций примерно
     дает суммарное время работы алгоритма (таймер `TIMER_total` в консоли).
     Если сумма примерно равна общему времени работы алгоритма, значит вы
     знаете, на что функция `skeletonize` тратит свое время.

  1. Далее запускаем демо-приложение с опцией `--save`, и без нее. Смотрим,
     какую часть времени приложение тратило на сохранение изображений. Далее
     всегда работаем без опции `--save`, поскольку она сильно замедляет работу
     алгоритма. Это понятно, поскольку в данном случае идет работа с жестким
     диском, и она нас точно не интересует с точки зрения работы алгоритма.

     ```txt
     $ cd <itseez-ws-2016-practice-build>
     $ ./bin/skeleton --image ./bin/testdata/sla.png --save
     $ ./bin/skeleton --image ./bin/testdata/sla.png
     ```

  1. Затем следует проанализировать разброс в замерах времени. Для этого
     запускаем демо-приложение несколько раз и фиксируем времена работы
     (например на листе бумаги). Оцениваем разброс значений, хотя бы просто "на
     глазок". Потом мы сравним эти значения с теми, что дают тесты
     производительности.

### Анализ метрик производительности

В тестовую сборку уже включен некий тест производительности, и в этом разделе
мы научимся запускать его, сохранять метрики производительности в XML-файл, и
затем анализировать их при помощи вспомогательных скриптов.

  1. Итак, первым делом стоит запустить сборку с тестами на производительность
     `perf_skeleton`. Это можно сделать при помощи команды ниже, и вы должны
     увидеть примерно следующий вывод.

     ```txt
     $ cd <itseez-ws-2016-practice-build>
     $ ./bin/perf_skeleton

     Time compensation is 25
     OpenCV version: 2.4.12
     Build type: release
     Parallel framework: UNKNOWN
     CPU features:
     [==========] Running 3 tests from 1 test case.
     [----------] Global test environment set-up.
     [----------] 3 tests from Size_Only_ImageResize
     [ RUN      ] Size_Only_ImageResize.ImageResize/0
     [ VALUE    ]  640x480
     [       OK ] Size_Only_ImageResize.ImageResize/0 (192 ms)
     [ RUN      ] Size_Only_ImageResize.ImageResize/1
     [ VALUE    ]  1280x720
     [       OK ] Size_Only_ImageResize.ImageResize/1 (583 ms)
     [ RUN      ] Size_Only_ImageResize.ImageResize/2
     [ VALUE    ]  1920x1080
     [       OK ] Size_Only_ImageResize.ImageResize/2 (1286 ms)
     [----------] 3 tests from Size_Only_ImageResize (2061 ms total)

     [----------] Global test environment tear-down
     [==========] 3 tests from 1 test case ran. (2061 ms total)
     [  PASSED  ] 3 tests.
     ```

  1. Однако в случае выше мы не сделали главного — мы не сохранили метрики
     производительности. Нужно понимать, что те числа, которые вывелись на
     консоль, не имеют отношения к производительности, поскольку функции
     выполнялись в цикле `TEST_CYCLE()` по несколько раз. Чтобы сохранить
     метрики, нужно указать имя XML-файла:

    ```txt
     $ cd <itseez-ws-2016-practice-build>
     $ ./bin/perf_skeleton --gtest_output=xml:perf_report.xml
    ```

  1. Далее стоит проанализировать содержимое собранного отчета. Детальную
     информацию по метрикам можно получить при помощи скрипта `report.py` из
     OpenCV:

     ```txt
      $ ../itseez-ws-2016-practice/3rdparty/opencv_ptest/misc/report.py ./perf_report.xml
     ```

     На консоль выведется полная статистика по метрикам:

     ```txt
               Name of Test                Number of     Number of   Min     Median  Geometric mean   Mean   Standard deviation
                                       collected samples outliers
     ImageResize::Size_Only::1280x720         100            2     5.40 ms  5.44 ms     5.66 ms     5.69 ms       0.59 ms
     ImageResize::Size_Only::1920x1080        100            0     12.21 ms 12.39 ms    12.95 ms    12.99 ms      1.04 ms
     ImageResize::Size_Only::640x480          100            4     1.80 ms  1.81 ms     1.91 ms     1.92 ms       0.25 ms
     ```

  1. Следующий скрипт, `summary.py`, позволяет сравнивать между собой несколько
     отчетов, например за разные дни или на разных этапах оптимизации. Мы для
     простоты всего-навсего запустим сборку `perf_skeleton` несколько раз, и
     сравним отчеты между собой.

     ```txt
     $ ./bin/perf_skeleton --gtest_output=xml:perf_report_1.xml
     $ ./bin/perf_skeleton --gtest_output=xml:perf_report_2.xml
     $ ./bin/perf_skeleton --gtest_output=xml:perf_report_3.xml
     $ ../itseez-ws-2016-practice/3rdparty/opencv_ptest/misc/summary.py ./perf_report*
     ```

  1. Сравните колебания метрик с теми, что мы наблюдали при запуске
     демо-приложения. Отчеты тестов производительности должны быть более
     устойчивыми, поскольку производится усреднение по нескольким запускам.

Более подробные инструкции по тому, как запускать и анализировать результаты
тестов на производительность, можно почитать в [инструкциях][using-perf-tests] к
OpenCV.

### Реализация тестов производительности

Остался последний, и возможно самый важный шаг — реализация тестов на
производительность. Рассмотрим как их можно добавить. Детальные инструкции
доступны в [документации][writing-perf-tests] к OpenCV.

  1. Первым делом стоит открыть файл `perf/perf_skeleton.cpp` и ознакомиться с
     уже имеющимся там тестом. Он содержит в себе все основные элементы тестов
     на производительность.

  1. Далее можно ознакомиться с заготовками еще двух тестов, которые имеются в
     файле, но закомментированы и имеют пустые тела. Эти тесты нужно реализовать
     по образу готового.

     - Регулярно отправляйте свои коды на тестирование Travis. Как обычно,
       постарайтесь реализовать какой-то очень простой фиктивный тест, создайте
       pull request, после чего обновляйте его всякий раз, как выполнен новый
       шаг работы (например добавлен тест).

     - Нужно стараться в тестах повторить те же параметры, что были использованы
       в демо-приложении. Это нужно для того, чтобы время работы тестов примерно
       соответствовало времени работы демо-приложения. Тогда если вы путем
       оптимизации добъетесь ускорения тестов, вы тем самым будете уверены в
       более быстрой работе приложения.

     - При этом нельзя ориентироваться исключительно на определенные сочетания
       параметров, поскольку в таком случае можно нарушить общность работы
       алгоритма. В связи с этим рекомендуется также добавить тесты, проверяющие
       скорость работы алгоритма и на других входных данных. Впоследствии стоит
       также отслеживать время работы и на этих данных.

     - При возникновении проблем и вопросов рекомендуется обращаться к
       [документации][writing-perf-tests] OpenCV и преподавателям.

  1. Аналогичным образом стоит реализовать тесты на все значимые шаги алгоритма
     скелетонизации. Это как минимум три основные функции:
     `ConvertColor_BGR2GRAY_BT709`, `ImageResize` и `GuoHallThinning`.

  1. Затем снова соберите несколько отчетов о производительности. Снова сравните
     колебания метрик с теми, что мы наблюдали при запуске демо-приложения, и
     проанализируйте их устойчивость.

На этом работу можно считать выполненной. Тем не менее, полезно будет написать
еще несколько тестов, собрать несколько отчетов о производительности,
поэкспериментировать c ключами сборки `perf_skeleton` (о них можно узнать,
запустив приложение с опцией `--help`).

<!-- LINKS -->

[writing-perf-tests]: https://github.com/Itseez/opencv/wiki/HowToWritePerfTests
[using-perf-tests]:   https://github.com/Itseez/opencv/wiki/HowToUsePerfTests
[feedback_day2]:      https://docs.google.com/forms/d/1UI3w6KDxHnz5-R50_4L1JZZN4XI8zu8EjmoL2ly82Jg/viewform